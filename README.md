
README for Cousera "Getting Data" Course Project
========================================================

This README file describes the run_analysis.R script that produces the tidy data set  for the Cousera "Getting Data" Course Project. Details of the structure and contents of the tidy data set itself are contained in the accompanying CodeBook.md [1] document.

 
Usage of the run_analysis.R script
--------------------------

**Description**

Reads UCI HAR Data in the current directory and writes a file containing a tidy data set of selected summary statistics from the original data.

**Synopsis**

    source("run_analysis.R")
    run_analysis()

**Arguments**

None.

**Input**

The input to the script is data collected in a study of human activity detected using smart phones[2]. The raw data[3] should be downloaded from the internet, unzipped and placed in the current directory under the subdirectory "UCI HAR Dataset".

If this subdirectory cannot be found, the script attempts to obtain the data from the internet; this may or may not be successful, depending on the user's platform and environment.
 
**Output**

Upon successful processing of the script a file is generated in the current directory, called "Tidy Means by Subject and Activity.txt". This is a space-delimited text file with column headers; further details of the file's structure and content may be found in the CodeBook document.

The function has no useful return value.

**Environment**

Run the script from an R console (verified for R V3.1.0 tunning on Windows 7 64 bits). 

**Notes**

Once the file is loaded within R, either form of invoking the script works. Sourcing the file invokes the function run_analysis() that does all the work.


Requirements and implementation
------------

### Script requirements

The requirements for the script were expressed[4] in the assignment as follows:
 
  1. Merges the training and the test sets to create one data set.
  2. Extracts only the measurements on the mean and standard deviation  for each measurement.
  3. Uses descriptive activity names to name the activities in the data set
  4. Appropriately labels the data set with descriptive variable names.
  5. Creates a second, independent tidy data set with the average of each variable for each activity and each subject. 

Below is a brief summary of how these requirements were interpreted and addressed. Further details are elsewhere in this document, in the CodeBook and in the comments to the code itself. Each item below corresponds to the respective requirement:

  1. The training and test sets are first transformed independently as required by #2, #3, and #4. The subject and activity labels (see #3) are prepended to the interim data frames as separate columns with names "subjectID" and "activity". Finally the test and training data are concatenated to form a combined cleaned data set. All this prep and merging work is performed by the support function getMergedCleanedData().
  2. The features.txt file, interpreted by the description in features_info.txt, identifies the nature of each measurement in the raw data. Those names including the element  mean() or std() relate to mean or standard deviation measurements, and a vector identifying matching variables to be used by read.table() is generated by the support function processFeatures(). *Note: these do not include non-summary statistics, such as "meanFreq" (frequency components to obtain a mean frequency) or average signal  vectors used in angle computations). Also, since the "Inertial Signals" files do not relate to means or standard deviations, they are skipped in this process.*
  3. Activity identifiers in the y_train.txt or y_test.txt files are read in, mapped via the activity to name the activities in the data set, and then used as a separate column in the working data frame. *Note: a similar process, minus the labelling step, is used to form another new column from the subjects file.*
  4. New variable names are generated by pattern matching and editing from the original feature names, but removing illegal R syntax, using more meaningful elements of names and cleaning up apparent typos. This processing occurs in the support function processFeatures(). The resultant names are fully described in the accompanying CodeBook.
  5. A new data frame is generated in the support function getTidyMeans() from the working one of #1-4 by applying the mean function to subsets of each data variable, grouped by subjectID and activity. The names of the group IDs is rest to the subjectID and activity, the table is sorted and then written to the output file.

### "Tidy data" requirements

The requirements to be met by the generated data set derive from the lecture "Components of Tidy Data" [5]:

1. Each variable you measure should be in one column
2. Each different observation of that variable should be in a different row
3. There should be one table for each "kind" of variable
4. If you have multiple tables, they should include a column in the table that allows them to be linked
5. Some other important tips
  - Include a row at the top of each file with variable names.
  - Make variable names human readable AgeAtDiagnosis instead of AgeDx
  - In general data should be saved in one file per table.

The output file format, as discussed in the CodeBook, complies with these requirements, and the considerations about multiple tables do not arise here.


References
----------

1.  CodeBook.md in the current repository, which describes the tidy data set generated by the run_analysis.R script here, and how to interpret it. 

2.  http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones 

3.  Raw data set (including original signal and feature descriptions) at
    https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip 

4.  Project requirements at https://class.coursera.org/getdata-005/human_grading ???

5. "Components of Tidy Data", slide 4 ("The Tidy Data") at http://jtleek.com/modules/03_GettingData/01_03_componentsOfTidyData/#4