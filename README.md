
README for Cousera "Getting Data" Course Project
========================================================

This README file describes the run_analysis.R script that produces the tidy data set  for the Cousera "Getting Data" Course Project. Details of the structure and contents of the tidy data set itself are contained in the accompanying CodeBook.md[^codebook] document.

 [^codebook]:CodeBook.md in the current repository, which describes the tidy data set generated by the run_analysis.R script here, and how to interpret it.
 
Usage of the run_analysis.R script
--------------------------
**Description**

Reads the directory "UCI HAR Dataset" in the current directory and writes a file containing a tidy data set of selected summary statistics from the original data

**Synopsis**

    source("run_analysis.R")
    run_analysis()

Run from an R console (verified for R V3.1.0 tunning on Windows 7 64 bits)

**Arguments**

None.

**Input**

The input to the script is data collected in a study of human activity detected using smart phones[^research]. The raw data[^rawdata] should be downloaded from the internet, unzipped and placed in the current directory under the subdirectory "UCI HAR Dataset".

 [^rawdata]:Raw data set (including original signal and feature descriptions) at 
https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip 

 [^research]: 
http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones 
 

**Output**

Upon successful processing of the script a file is generated in the current directory, called "Tidy Means by Subject and Activity.txt". This is a space-delimited text file with column headers; further details of the file's structure and content may be found in the CodeBook document.

The function has no useful return value.

**Notes**

Once the file is loaded within R, either form of invoking the script works. Sourcing the file invokes the function run_analysis() that does all the work.

 If this cannot be found, the script attempts to obtain it from the internet; this may or may not be successful, depending on the user's platform and environment.

Requirements and implementation
------------

The requirements for the script were expressed[^reqs] in the assignment as follows:
 
  1. Merges the training and the test sets to create one data set.
  2. Extracts only the measurements on the mean and standard deviation  for each measurement.
  3. Uses descriptive activity names to name the activities in the data set
  4. Appropriately labels the data set with descriptive variable names.
  5. Creates a second, independent tidy data set with the average of each variable for each activity and each subject. 

[^reqs]: Project requirements at https://class.coursera.org/getdata-005/human_grading

Below is a brief summary of how these requirements were interpreted and addressed. Further details are elsewhere in this document, in the CodeBook and in the comments to the code itself. Each item below corresponds to the respective requirement:

  1. The training and test sets are first transformed independently as required by #2, #3, and #4. The subject and activity labels (see #3) are prepended to the interim data frames as separate columns with names "subjectID" and "activity". Finally the test and training data are concatenated to form a combined cleaned data set. All this prep and merging work is performed by the support function getMergedCleanedData().
  2. The features.txt file, interpreted by the description in features_info.txt, identifies the nature of each measurement in the raw data. Those names including the element  mean() or std() relate to mean or standard deviation measurements, and a vector identifying matching variables to be used by read.table() is generated by the support function processFeatures(). *Note: these do not include non-summary statistics, such as "meanFreq" (frequency components to obtain a mean frequency) or average signal  vectors used in angle computations). Also, since the "Inertial Signals" files do not relate to means or standard deviations, they are skipped in this process.*
  3. Activity identifiers in the y_train.txt or y_test.txt files are read in, mapped via the activity to name the activities in the data set, and then used as a separate column in the working data frame. *Note: a similar process, minus the labelling step, is used to form another new column from the subjects file.*
  4. New variable names are generated by pattern matching and editing from the original feature names, but removing illegal R syntax, using more meaningful elements of names and cleaning up apparent typos. This processing occurs in the support function processFeatures(). The resultant names are fully described in the accompanying CodeBook.
  5. A new data frame is generated in the support function getTidyMeans() from the working one of #1-4 by applying the mean function to each data variable, grouped by subjectID and activity. The names of the group IDs is rest to the subjectID and activity, the table is sorted and then written to the output file.


References
----------


